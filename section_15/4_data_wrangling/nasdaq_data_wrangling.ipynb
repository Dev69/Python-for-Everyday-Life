{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as pdr\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our reference time period\n",
    "START = dt(1999, 1, 1)\n",
    "END = dt(2017, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a time range (timeindex) that we will use in a while\n",
    "ref_period = pd.date_range(START, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RETRIEVE DATA FOR NASDAQ STOCKS FROM QUANDL (might take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft Corp. stock (listed since 1986) \n",
    "msft = pdr.DataReader('MSFT', 'quandl', START, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon.com Inc. stock (listed since 2000)\n",
    "amzn = pdr.DataReader('AMZN', 'quandl', START, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabet Inc. (Google's holding) stock (listed since 2004)\n",
    "googl = pdr.DataReader('GOOGL', 'quandl', START, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facebook Inc. stock (listed since 2012)\n",
    "fb = pdr.DataReader('FB', 'quandl', START, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DROP UNUSED COLUMNS: \"ExDividend\" AND \"SplitRatio\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del msft['ExDividend']\n",
    "del amzn['ExDividend']\n",
    "del googl['ExDividend']\n",
    "del fb['ExDividend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del msft['SplitRatio']\n",
    "del amzn['SplitRatio']\n",
    "del googl['SplitRatio']\n",
    "del fb['SplitRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REBASE DATAFRAMES ON REFERENCE PERIOD\n",
    "\n",
    "# this will add/remove rows based on the actual dataframe and \n",
    "# will introduce NaN's on days for which data is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = msft.reindex(ref_period)\n",
    "amzn = amzn.reindex(ref_period)\n",
    "googl = googl.reindex(ref_period)\n",
    "fb = fb.reindex(ref_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE HIGH/LOW DAILY PEAKS FOR EACH STOCK\n",
    "daily_highs = {\n",
    "    'msft': msft['High'].max(),\n",
    "    'amzn': amzn['High'].max(),\n",
    "    'googl': googl['High'].max(),\n",
    "    'fb': fb['High'].max()\n",
    "}\n",
    "daily_lows = {\n",
    "    'msft': msft['Low'].min(),\n",
    "    'amzn': amzn['Low'].min(),\n",
    "    'googl': googl['Low'].min(),\n",
    "    'fb': fb['Low'].min()  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then derive highest/lowest daily peaks in the set\n",
    "highest_daily_peak = max(daily_highs.keys(), key=(lambda key: daily_highs[key]))\n",
    "lowest_daily_peak = min(daily_lows.keys(), key=(lambda key: daily_lows[key]))\n",
    "highest_daily_peak, lowest_daily_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE WHETHER EACH STOCK CLOSED ABOVE/BELOW THE AVERAGE DAILY CLOSING PRICE\n",
    "## ON EACH DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's create a new dataframe with daily closing prices\n",
    "daily_closes = pd.DataFrame({\n",
    "    'msft': msft['Close'],\n",
    "    'amzn': amzn['Close'],\n",
    "    'fb': fb['Close'],\n",
    "    'googl': googl['Close']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate the average closing price for every day and store it\n",
    "daily_closes['avg'] = daily_closes.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then check when the daily closing price is above the daily average and store it\n",
    "daily_closes['msft_above_daily_avg'] = msft['Close'] > daily_closes['avg']\n",
    "daily_closes['amzn_above_daily_avg'] = amzn['Close'] > daily_closes['avg']\n",
    "daily_closes['googl_above_daily_avg'] = googl['Close'] > daily_closes['avg']\n",
    "daily_closes['fb_above_daily_avg'] = fb['Close'] > daily_closes['avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and the winner is...\n",
    "days_above_daily_avg = {\n",
    "    'msft': daily_closes['msft_above_daily_avg'].sum(),\n",
    "    'amzn': daily_closes['amzn_above_daily_avg'].sum(),\n",
    "    'googl': daily_closes['googl_above_daily_avg'].sum(),\n",
    "    'fb': daily_closes['fb_above_daily_avg'].sum()  \n",
    "}\n",
    "most_durable_above_daily_avg = max(days_above_daily_avg.keys(),\n",
    "                                   key=(lambda key: days_above_daily_avg[key]))\n",
    "most_durable_above_daily_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNDERSAMPLE DATA: 1-MONTH WIDE BINS, FILLED WITH MEAN CLOSE PRICE ON THE PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_msft = msft.resample('M').mean()\n",
    "monthly_amzn = amzn.resample('M').mean()\n",
    "monthly_googl = googl.resample('M').mean()\n",
    "monthly_fb = fb.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE HIGH/LOW MONTHLY PEAKS FOR EACH STOCK\n",
    "monthly_highs = {\n",
    "    'msft': monthly_msft['High'].max(),\n",
    "    'amzn': monthly_amzn['High'].max(),\n",
    "    'googl': monthly_googl['High'].max(),\n",
    "    'fb': monthly_fb['High'].max()\n",
    "}\n",
    "monthly_lows = {\n",
    "    'msft': monthly_msft['Low'].min(),\n",
    "    'amzn': monthly_amzn['Low'].min(),\n",
    "    'googl': monthly_googl['Low'].min(),\n",
    "    'fb': monthly_fb['Low'].min()  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then derive highest/lowest monthly peaks in the set\n",
    "highest_monthly_peak = max(monthly_highs.keys(), key=(lambda key: monthly_highs[key]))\n",
    "lowest_monthly_peak = min(monthly_lows.keys(), key=(lambda key: monthly_lows[key]))\n",
    "highest_monthly_peak, lowest_monthly_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE WHETHER EACH STOCK CLOSED ABOVE/BELOW THE AVERAGE MONTHLY CLOSING PRICE\n",
    "## ON EACH MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's create a new dataframe with monthly closing prices\n",
    "monthly_closes = pd.DataFrame({\n",
    "    'msft': monthly_msft['Close'],\n",
    "    'amzn': monthly_amzn['Close'],\n",
    "    'fb': monthly_fb['Close'],\n",
    "    'googl': monthly_googl['Close']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate the average closing price for every month and store it\n",
    "monthly_closes['avg'] = monthly_closes.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then check when the monthly closing price is above the monthly average and store it\n",
    "monthly_closes['msft_above_monthly_avg'] = monthly_msft['Close'] > monthly_closes['avg']\n",
    "monthly_closes['amzn_above_monthly_avg'] = monthly_amzn['Close'] > monthly_closes['avg']\n",
    "monthly_closes['googl_above_monthly_avg'] = monthly_googl['Close'] > monthly_closes['avg']\n",
    "monthly_closes['fb_above_monthly_avg'] = monthly_fb['Close'] > monthly_closes['avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and the winner is...\n",
    "months_above_monthly_avg = {\n",
    "    'msft': monthly_closes['msft_above_monthly_avg'].sum(),\n",
    "    'amzn': monthly_closes['amzn_above_monthly_avg'].sum(),\n",
    "    'googl': monthly_closes['googl_above_monthly_avg'].sum(),\n",
    "    'fb': monthly_closes['fb_above_monthly_avg'].sum()  \n",
    "}\n",
    "most_durable_above_monthly_avg = max(months_above_monthly_avg.keys(),\n",
    "                                   key=(lambda key: months_above_monthly_avg[key]))\n",
    "most_durable_above_monthly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE ALL DATAFRAMES TO CSV FILES\n",
    "msft.to_csv('msft.csv')\n",
    "amzn.to_csv('amzn.csv')\n",
    "googl.to_csv('googl.csv')\n",
    "fb.to_csv('fb.csv')\n",
    "monthly_msft.to_csv('monthly_msft.csv')\n",
    "monthly_amzn.to_csv('monthly_amzn.csv')\n",
    "monthly_googl.to_csv('monthly_googl.csv')\n",
    "monthly_fb.to_csv('monthly_fb.csv')\n",
    "daily_closes.to_csv('daily_closes.csv')\n",
    "monthly_closes.to_csv('monthly_closes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
